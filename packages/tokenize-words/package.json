{
  "name": "tokenize-words",
  "author": "gusalbukrk",
  "version": "0.0.3-alpha.0",
  "description": "Break down text into array of words.",
  "license": "MIT",
  "keywords": [
    "tokenizer",
    "tokenization",
    "segmentation",
    "word segmentation",
    "NLP",
    "natural language processing"
  ],
  "type": "module",
  "types": "dist/index.d.ts",
  "main": "dist/bundle.cjs",
  "engines": {
    "node": ">=14.0.0"
  },
  "exports": {
    "import": "./dist/bundle.js",
    "require": "./dist/bundle.cjs"
  },
  "files": [
    "dist",
    "src",
    "!src/**/__tests__/",
    "!src/**/__spec__/",
    "!src/**/*.test.[jt]s",
    "!src/**/*.test.[jt]sx",
    "!src/**/*.spec.[jt]s",
    "!src/**/*.spec.[jt]sx"
  ],
  "scripts": {
    "build": "rollup -c ../../rollup.config.js",
    "lint": "eslint src/ --fix && cspell \"**\" -c ../../cspell.config.cjs --no-progress",
    "postbuild": "eslint dist/index.d.ts --fix --no-ignore && replace-in-file --configFile=../../.replace-in-file.cjs",
    "postpublish": "../../node_modules/rimraf/bin.js dist/",
    "prepublishOnly": "yarn build",
    "test": "jest --passWithNoTests"
  },
  "dependencies": {
    "stopwords-utils": "link:../stopwords-utils",
    "xlorem-common": "link:../common"
  }
}
